"""
Jetson ä¼˜åŒ–ç‰ˆ Gradio Web UI - ç¯å…·3Då®šä½å®æ—¶æ£€æµ‹
- ç›´æ¥ä½¿ç”¨æœ¬åœ°æ‘„åƒå¤´ (USB/CSI)
- ç§»é™¤æµ‹è¯•ä»£ç å’Œå†—ä½™åŠŸèƒ½
- ä¸“æ³¨äºç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
"""

import gradio as gr
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import torch
from pipeline import LightLocalization3D
import time

# å…¨å±€å˜é‡
pipeline = None

def initialize_pipeline():
    """åˆå§‹åŒ–æ£€æµ‹æµæ°´çº¿"""
    global pipeline
    if pipeline is None:
        print("ğŸš€ åˆå§‹åŒ–ç¯å…·æ£€æµ‹æµæ°´çº¿...")
        pipeline = LightLocalization3D(
            detection_model="google/owlv2-large-patch14-ensemble",
            feature_model="facebook/dinov2-large",
            depth_model="depth-anything/Depth-Anything-V2-Large-hf"
        )
        
        # å°è¯•å¯ç”¨TensorRTåŠ é€Ÿ
        try:
            if hasattr(pipeline, 'enable_tensorrt'):
                pipeline.enable_tensorrt()
                print("âœ… TensorRTåŠ é€Ÿå·²å¯ç”¨")
        except Exception as e:
            print(f"âš ï¸ TensorRTåŠ é€Ÿå¯ç”¨å¤±è´¥: {e}")
        
        print("âœ… æµæ°´çº¿åˆå§‹åŒ–å®Œæˆ!")
    return pipeline

def draw_detections(image, detections):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
    if isinstance(image, np.ndarray):
        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    
    draw = ImageDraw.Draw(image)
    
    try:
        font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 16)
        font_small = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 12)
    except:
        font = ImageFont.load_default()
        font_small = font
    
    colors = [
        (255, 0, 0), (0, 255, 0), (0, 0, 255),
        (255, 255, 0), (255, 0, 255), (0, 255, 255)
    ]
    
    for idx, det in enumerate(detections):
        box = det['box']
        x1, y1, x2, y2 = map(int, box)
        color = colors[idx % len(colors)]
        
        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)
        
        label = det['label']
        confidence = det['confidence']
        distance = det.get('distance', None)
        
        if distance:
            text = f"{label}\n{confidence:.1%}\n{distance:.2f}m"
        else:
            text = f"{label}\n{confidence:.1%}"
        
        bbox = draw.textbbox((x1, y1-60), text, font=font_small)
        draw.rectangle([bbox[0]-2, bbox[1]-2, bbox[2]+2, bbox[3]+2], fill=(0, 0, 0, 200))
        draw.text((x1, y1-60), text, fill=color, font=font_small)
    
    return np.array(image)

def generate_depth_image(depth_map):
    """ç”Ÿæˆæ·±åº¦å›¾å¯è§†åŒ–"""
    if depth_map is None:
        return None
    
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')
    
    fig, ax = plt.subplots(figsize=(8, 6))
    im = ax.imshow(depth_map, cmap='plasma')
    ax.set_title('Depth Map', fontsize=14)
    ax.axis('off')
    plt.colorbar(im, ax=ax, label='Depth (normalized)')
    
    fig.canvas.draw()
    buf = fig.canvas.buffer_rgba()
    depth_image = np.asarray(buf)[:, :, :3]
    plt.close(fig)
    
    return depth_image

def process_image(image, confidence_threshold, show_depth):
    """å¤„ç†å•å¼ å›¾åƒ"""
    try:
        if image is None:
            return None, None, "âŒ è¯·å…ˆä¸Šä¼ å›¾ç‰‡!"
        
        start_time = time.time()
        pipe = initialize_pipeline()
        
        # æ ‡å‡†åŒ–å›¾åƒæ ¼å¼
        if isinstance(image, Image.Image):
            image = np.array(image)
        
        if len(image.shape) == 2:
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
        elif image.shape[2] == 4:
            image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
        
        # æ‰§è¡Œæ£€æµ‹
        result = pipe.process_image(
            image,
            confidence_threshold=confidence_threshold,
            compute_depth=show_depth,
            compute_distance=show_depth
        )
        
        detections = result['detections']
        depth_map = result.get('depth_map')
        
        output_image = draw_detections(image.copy(), detections)
        process_time = time.time() - start_time
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = f"""
### ğŸ“Š æ£€æµ‹ç»Ÿè®¡
- **æ£€æµ‹æ•°é‡**: {len(detections)} ä¸ªç¯å…·
- **å¤„ç†æ—¶é—´**: {process_time:.2f}ç§’
- **ç½®ä¿¡åº¦é˜ˆå€¼**: {confidence_threshold:.2f}

### ğŸ” æ£€æµ‹è¯¦æƒ…
"""
        
        for i, det in enumerate(detections[:10], 1):
            stats += f"\n**ç›®æ ‡ {i}**\n"
            stats += f"- ç±»å‹: {det['label']}\n"
            stats += f"- ç½®ä¿¡åº¦: {det['confidence']:.2%}\n"
            if det.get('distance'):
                stats += f"- è·ç¦»: {det['distance']:.2f}m\n"
        
        depth_image = generate_depth_image(depth_map) if show_depth else None
        
        return output_image, depth_image, stats
        
    except Exception as e:
        import traceback
        error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}\n\n```\n{traceback.format_exc()}\n```"
        return image, None, error_msg

def process_webcam_frame(frame, confidence_threshold, show_depth):
    """å¤„ç†æ‘„åƒå¤´å¸§ - Jetson ç›´æ¥ä½¿ç”¨æœ¬åœ°æ‘„åƒå¤´"""
    if frame is None:
        return None, None, "â³ ç­‰å¾…æ‘„åƒå¤´è¾“å…¥..."
    
    try:
        start_time = time.time()
        pipe = initialize_pipeline()
        
        # æ ‡å‡†åŒ–å›¾åƒæ ¼å¼
        if isinstance(frame, Image.Image):
            frame = np.array(frame)
        
        if len(frame.shape) == 2:
            frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)
        elif frame.shape[2] == 4:
            frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2RGB)
        
        # æ‰§è¡Œæ£€æµ‹
        result = pipe.process_image(
            frame,
            confidence_threshold=confidence_threshold,
            compute_depth=show_depth,
            compute_distance=True
        )
        
        detections = result['detections']
        depth_map = result.get('depth_map')
        
        # ç»˜åˆ¶æ£€æµ‹ç»“æœ
        output_frame = draw_detections(frame.copy(), detections)
        
        # æ·»åŠ æ€§èƒ½ä¿¡æ¯åˆ°ç”»é¢
        process_time = time.time() - start_time
        fps = 1.0 / process_time if process_time > 0 else 0
        cv2.putText(output_frame, f"FPS: {fps:.1f}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(output_frame, f"Detections: {len(detections)}", (10, 70),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = f"""
### ğŸ“Š å®æ—¶æ£€æµ‹ç»Ÿè®¡
- **æ£€æµ‹æ•°é‡**: {len(detections)} ä¸ªç¯å…·
- **å¤„ç†æ—¶é—´**: {process_time:.2f}ç§’
- **FPS**: {fps:.2f}
- **ç½®ä¿¡åº¦é˜ˆå€¼**: {confidence_threshold:.2f}

### ğŸ” æ£€æµ‹è¯¦æƒ…
"""
        
        for i, det in enumerate(detections[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
            stats += f"\n**ç›®æ ‡ {i}**: {det['label']} ({det['confidence']:.1%})"
            if det.get('distance'):
                stats += f" - {det['distance']:.2f}m"
        
        depth_image = generate_depth_image(depth_map) if show_depth else None
        
        return output_frame, depth_image, stats
        
    except Exception as e:
        import traceback
        error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}\n\n```\n{traceback.format_exc()}\n```"
        return frame, None, error_msg

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="ç¯å…·3Då®šä½æ£€æµ‹ç³»ç»Ÿ (Jetson)", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ”¦ ç¯å…·3Då®šä½æ£€æµ‹ç³»ç»Ÿ (Jetson AGX Orin)
    
    åŸºäº **OWLv2 + DINOv3 + Depth Anything V2** çš„æ™ºèƒ½ç¯å…·æ£€æµ‹ä¸3Då®šä½
    
    âš¡ **ç¡¬ä»¶**: Jetson AGX Orin 64GB | **ä¼˜åŒ–**: TensorRT FP16/INT8 | **æ‘„åƒå¤´**: USB/CSI ç›´è¿
    """)
    
    with gr.Tabs():
        # Tab 1: å›¾åƒæ£€æµ‹
        with gr.Tab("ğŸ“¸ å›¾åƒæ£€æµ‹"):
            gr.Markdown("""
            ### ğŸ“· å•å¼ å›¾ç‰‡æ£€æµ‹
            
            ä¸Šä¼ å›¾ç‰‡è¿›è¡Œå®Œæ•´çš„ç¯å…·æ£€æµ‹ã€è·ç¦»ä¼°è®¡å’Œæ·±åº¦åˆ†æ
            """)
            
            with gr.Row():
                with gr.Column():
                    input_image = gr.Image(label="ä¸Šä¼ å›¾åƒ", type="numpy")
                    confidence_slider = gr.Slider(
                        minimum=0.05,
                        maximum=0.5,
                        value=0.15,
                        step=0.05,
                        label="ç½®ä¿¡åº¦é˜ˆå€¼"
                    )
                    show_depth_check = gr.Checkbox(
                        label="æ˜¾ç¤ºæ·±åº¦å›¾",
                        value=True
                    )
                    detect_btn = gr.Button("ğŸ” å¼€å§‹æ£€æµ‹", variant="primary", size="lg")
                
                with gr.Column():
                    output_image = gr.Image(label="æ£€æµ‹ç»“æœ")
                    depth_image = gr.Image(label="æ·±åº¦å›¾", visible=True)
            
            with gr.Row():
                stats_output = gr.Markdown(label="æ£€æµ‹ç»Ÿè®¡")
            
            detect_btn.click(
                fn=process_image,
                inputs=[input_image, confidence_slider, show_depth_check],
                outputs=[output_image, depth_image, stats_output]
            )
        
        # Tab 2: æ‘„åƒå¤´å®æ—¶æ£€æµ‹ (Jetson ç›´è¿æœ¬åœ°æ‘„åƒå¤´)
        with gr.Tab("ğŸ“¹ æ‘„åƒå¤´å®æ—¶æ£€æµ‹"):
            gr.Markdown("""
            ### ğŸ¥ å®æ—¶æ‘„åƒå¤´æ£€æµ‹
            
            **Jetson æœ¬åœ°æ‘„åƒå¤´**:
            - âœ… USB æ‘„åƒå¤´: /dev/video0, /dev/video1
            - âœ… CSI æ‘„åƒå¤´: Jetson æ¿è½½æ‘„åƒå¤´æ¥å£
            - âœ… è‡ªåŠ¨é—´éš”é‡‡æ · (æ¯5ç§’æ£€æµ‹ä¸€æ¬¡)
            - âœ… å®Œæ•´åŠŸèƒ½: æ£€æµ‹ + è·ç¦» + æ·±åº¦
            
            **ä½¿ç”¨æ–¹æ³•**:
            1. ç‚¹å‡»æ‘„åƒå¤´å›¾æ ‡å¯åŠ¨ (Docker å·²æ˜ å°„ /dev/video0)
            2. è‡ªåŠ¨æ¯5ç§’æ£€æµ‹ä¸€æ¬¡
            3. è°ƒæ•´å‚æ•°å®æ—¶ç”Ÿæ•ˆ
            
            **æ€§èƒ½æç¤º**:
            - æ¨ç†æ—¶é—´: 0.5-1.5ç§’/å¸§ (FP16)
            - å…³é—­æ·±åº¦å›¾å¯æå‡30%é€Ÿåº¦
            - é€‚åˆé•¿æ—¶é—´å®æ—¶ç›‘æ§
            """)
            
            with gr.Row():
                with gr.Column():
                    webcam_input = gr.Image(
                        label="ğŸ“¹ æœ¬åœ°æ‘„åƒå¤´ (è‡ªåŠ¨æ¯5ç§’æ£€æµ‹)",
                        sources=["webcam"],
                        type="numpy",
                        streaming=True
                    )
                    with gr.Row():
                        webcam_confidence = gr.Slider(
                            minimum=0.05,
                            maximum=0.5,
                            value=0.15,
                            step=0.05,
                            label="ç½®ä¿¡åº¦é˜ˆå€¼"
                        )
                        webcam_depth_check = gr.Checkbox(
                            label="æ˜¾ç¤ºæ·±åº¦å›¾",
                            value=False
                        )
                
                with gr.Column():
                    webcam_output = gr.Image(label="æ£€æµ‹ç»“æœ")
                    webcam_depth = gr.Image(label="æ·±åº¦å›¾")
            
            with gr.Row():
                webcam_stats = gr.Markdown(
                    label="å®æ—¶ç»Ÿè®¡", 
                    value="ğŸ“¹ **å¯åŠ¨æ‘„åƒå¤´åä¼šè‡ªåŠ¨æ¯5ç§’æ£€æµ‹ä¸€æ¬¡...**"
                )
            
            # è§†é¢‘æµè‡ªåŠ¨æ£€æµ‹ (æ¯5ç§’)
            webcam_input.stream(
                fn=process_webcam_frame,
                inputs=[webcam_input, webcam_confidence, webcam_depth_check],
                outputs=[webcam_output, webcam_depth, webcam_stats],
                stream_every=5
            )
        
        # Tab 3: ç³»ç»Ÿä¿¡æ¯
        with gr.Tab("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯"):
            gr.Markdown("""
            ### ğŸ–¥ï¸ Jetson AGX Orin 64GB è§„æ ¼
            
            | é¡¹ç›® | å‚æ•° |
            |------|------|
            | **GPU** | 2048-core NVIDIA Ampere |
            | **å†…å­˜** | 64GB LPDDR5 |
            | **AI æ€§èƒ½** | 275 TOPS (INT8) |
            | **åŠŸè€—** | 15W-60W (MAXN æ¨¡å¼) |
            
            ### ğŸ¤– AI æ¨¡å‹æ¶æ„
            
            | ç»„ä»¶ | æ¨¡å‹ | ç”¨é€” |
            |------|------|------|
            | **æ£€æµ‹å™¨** | OWLv2-Large | é›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹ |
            | **ç‰¹å¾æå–** | DINOv3-Large | è‡ªç›‘ç£è§†è§‰ç‰¹å¾ |
            | **æ·±åº¦ä¼°è®¡** | Depth Anything V2 Large | å•ç›®æ·±åº¦ä¼°è®¡ |
            | **åŠ é€Ÿ** | TensorRT FP16/INT8 | æ¨ç†åŠ é€Ÿ |
            
            ### âš¡ æ€§èƒ½ä¼˜åŒ–
            
            - âœ… **TensorRT FP16**: 2-3å€é€Ÿåº¦æå‡
            - âœ… **INT8 é‡åŒ–**: å¯é€‰,é€‚åˆæè‡´æ€§èƒ½éœ€æ±‚
            - âœ… **é—´éš”é‡‡æ ·**: é™ä½ GPU è´Ÿè½½
            - âœ… **æŒ‰éœ€è®¡ç®—**: å¯é€‰æ‹©æ˜¯å¦è®¡ç®—æ·±åº¦å›¾
            
            ### ğŸ“¹ æ‘„åƒå¤´æ”¯æŒ
            
            - **USB æ‘„åƒå¤´**: /dev/video0, /dev/video1
            - **CSI æ‘„åƒå¤´**: Jetson æ¿è½½æ¥å£
            - **Docker æ˜ å°„**: å·²åœ¨ docker-compose ä¸­é…ç½®
            
            ### ğŸ”§ æ€§èƒ½ç›‘æ§
            
            åœ¨ Jetson ç»ˆç«¯è¿è¡Œ:
            
            ```bash
            # å®æ—¶ç›‘æ§
            sudo tegrastats
            
            # æˆ–ä½¿ç”¨ jtop
            sudo jtop
            
            # è®¾ç½®æœ€å¤§æ€§èƒ½æ¨¡å¼
            sudo nvpmodel -m 0
            sudo jetson_clocks
            ```
            
            ### ğŸ“‚ é¡¹ç›®ä¿¡æ¯
            
            - **GitHub**: [Luminaire-Testing-and-Monocular-Depth-Distance](https://github.com/warchanged/Luminaire-Testing-and-Monocular-Depth-Distance)
            - **éƒ¨ç½²**: Docker + NVIDIA Runtime
            - **æ–‡æ¡£**: æŸ¥çœ‹ `JETSON_DOCKER_GUIDE.md`
            """)

if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        allowed_paths=["/"]
    )
