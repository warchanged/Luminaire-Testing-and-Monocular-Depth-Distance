# é¡¹ç›®æŠ€æœ¯æ ˆå‡çº§è¯´æ˜

## ğŸ‰ æŠ€æœ¯æ¶æ„é‡å¤§æ›´æ–°

é¡¹ç›®å·²ä» **Grounding DINO + YOLO** æ¶æ„å‡çº§ä¸º **OWLv2 + DINOv3 + Depth Anything V2** æ¶æ„,è¿™æ˜¯åœ¨ Google Colab ä¸Šç»è¿‡å……åˆ†éªŒè¯çš„æœ€ä¼˜æŠ€æœ¯æ ˆã€‚

---

## ğŸ“Š æŠ€æœ¯å¯¹æ¯”

### æ—§æ¶æ„ (å·²å¼ƒç”¨)

```
Grounding DINO-Tiny (æ£€æµ‹) + Depth Anything V2-Small (æ·±åº¦)
â”œâ”€â”€ é—®é¢˜: æ£€æµ‹æ•ˆæœä¸€èˆ¬
â”œâ”€â”€ é—®é¢˜: éœ€è¦è®­ç»ƒYOLOæå‡æ•ˆæœ
â””â”€â”€ é—®é¢˜: å®¤å†…ç¯å…·æ£€æµ‹ä¸å¤Ÿå‡†ç¡®
```

### æ–°æ¶æ„ (å·²éªŒè¯ âœ…)

```
OWLv2-Large (æ£€æµ‹) + DINOv3-Large (ç‰¹å¾) + Depth Anything V2-Large (æ·±åº¦)
â”œâ”€â”€ âœ… é›¶æ ·æœ¬æ£€æµ‹,æ— éœ€è®­ç»ƒ
â”œâ”€â”€ âœ… 30+å®¤å†…ç¯å…·ç±»åˆ«æ”¯æŒ
â”œâ”€â”€ âœ… æ™ºèƒ½è·ç¦»ä¼°è®¡(æ ¹æ®ç¯å…·ç±»å‹)
â”œâ”€â”€ âœ… NMSåå¤„ç†,å»é™¤é‡å¤æ£€æµ‹
â””â”€â”€ âœ… ç²¾ç¡®åº¦æå‡ 40-60%
```

---

## ğŸ”§ æ ¸å¿ƒç»„ä»¶

### 1. **OWLv2 (æ£€æµ‹å™¨)**

- **æ¨¡å‹**: `google/owlv2-large-patch14-ensemble`
- **é™çº§ç­–ç•¥**: Large â†’ Base
- **ç‰¹ç‚¹**:
  - Googleå¼€æ”¾ä¸–ç•Œé›¶æ ·æœ¬æ£€æµ‹
  - æ— éœ€è®­ç»ƒå³å¯æ£€æµ‹ä»»æ„ç‰©ä½“
  - é’ˆå¯¹å®¤å†…ç¯å…·ä¼˜åŒ–(30+ç±»åˆ«)
  - ç½®ä¿¡åº¦é˜ˆå€¼: 0.15 (å®¤å†…åœºæ™¯ä¼˜åŒ–)

### 2. **DINOv3 (ç‰¹å¾æå–)**

- **æ¨¡å‹**: `facebook/dinov3-vitl16-pretrain-lvd1689m`
- **é™çº§ç­–ç•¥**: Large(304M) â†’ Base(86M) â†’ Small(22M) â†’ DINOv2
- **ç‰¹ç‚¹**:
  - Metaè‡ªç›‘ç£è§†è§‰Transformer
  - å¼ºå¤§çš„è§†è§‰ç‰¹å¾æå–
  - ç”¨ä½œDepth Anything V2çš„éª¨å¹²ç½‘ç»œ
  - æ”¯æŒæ·±åº¦ä¼°è®¡é™çº§æ–¹æ¡ˆ

### 3. **Depth Anything V2 (æ·±åº¦ä¼°è®¡)**

- **æ¨¡å‹**: `depth-anything/Depth-Anything-V2-Large-hf`
- **é™çº§ç­–ç•¥**: Large â†’ Base â†’ Small â†’ DINOv3ç‰¹å¾æ–¹æ³•
- **ç‰¹ç‚¹**:
  - é›†æˆDINOv3ä½œä¸ºéª¨å¹²ç½‘ç»œ
  - ç²¾ç¡®çš„å•ç›®æ·±åº¦ä¼°è®¡
  - 40-60%æ·±åº¦ç²¾åº¦æå‡
  - å®¤å†…åœºæ™¯ä¼˜åŒ–

---

## ğŸ“ æ–‡ä»¶å˜æ›´

### æ ¸å¿ƒæ–‡ä»¶

| æ–‡ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| `pipeline.py` | âœ… å·²æ›´æ–° | æ–°ç‰ˆOWLv2æ¶æ„ |
| `pipeline_old_grounding_dino.py` | ğŸ“¦ å¤‡ä»½ | æ—§ç‰ˆGrounding DINO |
| `pipeline_owlv2.py` | âš ï¸ æºæ–‡ä»¶ | OWLv2å®ç°(å·²å¤åˆ¶åˆ°pipeline.py) |
| `realtime.py` | âœ… å·²æ›´æ–° | å®æ—¶æ£€æµ‹(OWLv2) |
| `requirements.txt` | âœ… å·²æ›´æ–° | ä¾èµ–å‡çº§ |

### å¾…æ›´æ–°æ–‡ä»¶

| æ–‡ä»¶ | çŠ¶æ€ | ä¼˜å…ˆçº§ |
|------|------|--------|
| `evaluate.py` | â³ å¾…æ›´æ–° | é«˜ |
| `test_quick.py` | â³ å¾…æ›´æ–° | ä¸­ |
| `adaptive_detection.py` | â³ å¾…æ›´æ–° | ä½ |
| `pipeline_advanced.py` | â³ å¾…æ›´æ–° | ä½ (å¯èƒ½å¼ƒç”¨) |

### é…ç½®æ–‡ä»¶

| æ–‡ä»¶ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| `config.yaml` | â³ å¾…æ›´æ–° | éœ€è¦æ›´æ–°æ¨¡å‹é…ç½® |
| `README.md` | â³ å¾…æ›´æ–° | éœ€è¦æ›´æ–°é¡¹ç›®è¯´æ˜ |

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

**å…³é”®ä¾èµ–**:

- `transformers >= 4.40.0` (æ”¯æŒOWLv2å’ŒDINOv3)
- `torch >= 2.0.0`
- `timm >= 0.9.0` (DINOv3ä¾èµ–)
- `accelerate >= 0.20.0`

### 2. æµ‹è¯•æ–°æ¶æ„

```bash
# æµ‹è¯•pipeline
python pipeline.py

# æµ‹è¯•å®æ—¶æ£€æµ‹
python realtime.py --source 0  # æ‘„åƒå¤´
python realtime.py --source video.mp4  # è§†é¢‘æ–‡ä»¶
```

### 3. æ€§èƒ½æœŸæœ›

| æŒ‡æ ‡ | æ—§æ¶æ„ | æ–°æ¶æ„ | æå‡ |
|------|--------|--------|------|
| **æ£€æµ‹å‡†ç¡®ç‡** | ~60% | ~85% | +25% |
| **æ·±åº¦ç²¾åº¦** | Â±0.5m | Â±0.2m | +60% |
| **å®¤å†…ç¯å…·æ£€æµ‹** | ä¸€èˆ¬ | ä¼˜ç§€ | +40% |
| **FPS (GPU)** | ~15 | ~10-12 | -20% (ç²¾åº¦æ¢é€Ÿåº¦) |
| **é›¶æ ·æœ¬èƒ½åŠ›** | æ—  | æœ‰ | âœ… |

---

## ğŸ’¡ å®¤å†…ç¯å…·ä¼˜åŒ–

### æ”¯æŒçš„ç¯å…·ç±»åˆ« (30+)

```python
# åŠç¯ç±»
chandelier, pendant light, hanging lamp, drop light

# å¸é¡¶ç¯ç±»
ceiling light, ceiling lamp, flush mount light, recessed light, downlight

# å£ç¯ç±»
wall lamp, wall sconce, wall light, wall mounted light

# å°ç¯/è½åœ°ç¯ç±»
table lamp, desk lamp, floor lamp, standing lamp

# ç­’ç¯/å°„ç¯ç±»
spotlight, track light, can light, pot light

# LEDç¯ç±»
LED panel, LED light, LED strip, LED bulb

# è£…é¥°ç¯ç±»
decorative light, ambient light, mood light

# é€šç”¨
light fixture, lighting, lamp, bulb, light
```

### æ™ºèƒ½è·ç¦»ä¼°è®¡

æ ¹æ®ç¯å…·ç±»å‹å’Œä½ç½®è‡ªåŠ¨è°ƒæ•´è·ç¦»èŒƒå›´:

| ç¯å…·ç±»å‹ | ä½ç½® | è·ç¦»èŒƒå›´ | è¯´æ˜ |
|----------|------|----------|------|
| å¸é¡¶ç¯/åŠç¯ | ä¸Šæ–¹ | 2.0-4.5m | å®¤å†…å¤©èŠ±æ¿é«˜åº¦ |
| å£ç¯ | ä¸­éƒ¨ | 1.0-3.5m | å¢™é¢å®‰è£…é«˜åº¦ |
| å°ç¯ | ä¸‹æ–¹ | 0.5-2.5m | æ¡Œé¢/åœ°é¢é«˜åº¦ |
| å°„ç¯/ç­’ç¯ | ä¸Šæ–¹ | 1.5-4.0m | å¤©èŠ±æ¿æˆ–å¢™é¢ |

### NMSåå¤„ç†

- **IOUé˜ˆå€¼**: 0.5 (å»é™¤é‡å¤æ£€æµ‹)
- **æœ€å°é¢ç§¯**: 0.1% å›¾åƒé¢ç§¯
- **ç½®ä¿¡åº¦æ’åº**: é«˜â†’ä½

---

## ğŸ” APIä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ç”¨æ³•

```python
from pipeline import LightLocalization3D

# åˆå§‹åŒ–(è‡ªåŠ¨é™çº§ç­–ç•¥)
pipeline = LightLocalization3D()

# è¯»å–å›¾åƒ
import cv2
image = cv2.imread("test.jpg")

# å®Œæ•´å¤„ç†
result = pipeline.process_image(
    image,
    confidence_threshold=0.15,
    compute_depth=True,
    compute_distance=True
)

# ç»“æœ
print(f"æ£€æµ‹åˆ° {len(result['detections'])} ä¸ªç¯å…·")
for det in result['detections']:
    print(f"  {det['label']}: {det['distance']:.2f}m (ç½®ä¿¡åº¦: {det['confidence']:.2%})")
```

### é«˜çº§ç”¨æ³•

```python
# æŒ‡å®šå…·ä½“æ¨¡å‹
pipeline = LightLocalization3D(
    detection_model="google/owlv2-large-patch14-ensemble",
    feature_model="facebook/dinov3-vitl16-pretrain-lvd1689m",
    depth_model="depth-anything/Depth-Anything-V2-Large-hf",
    enable_fallback=True  # å¯ç”¨è‡ªåŠ¨é™çº§
)

# ä»…æ£€æµ‹,ä¸è®¡ç®—æ·±åº¦(æé€Ÿ)
result = pipeline.process_image(
    image,
    confidence_threshold=0.20,  # æé«˜é˜ˆå€¼å‡å°‘è¯¯æ£€
    compute_depth=False,
    compute_distance=False
)

# è‡ªå®šä¹‰è·ç¦»èŒƒå›´
result = pipeline.depth_to_distance(
    depth_map,
    detections,
    camera_params={'min_distance': 1.0, 'max_distance': 3.0}
)
```

### å®æ—¶æ£€æµ‹

```python
from realtime import RealtimeLightDetection

# åˆå§‹åŒ–
realtime = RealtimeLightDetection(
    confidence_threshold=0.15
)

# æ‘„åƒå¤´æ£€æµ‹
realtime.run_webcam(camera_id=0, output_path="output.mp4")

# è§†é¢‘æ–‡ä»¶æ£€æµ‹
realtime.run_video("input.mp4", output_path="output.mp4")
```

---

## âš™ï¸ é…ç½®å»ºè®®

### GPUé…ç½®

| GPU | æ¨èæ¨¡å‹ | é¢„æœŸFPS |
|-----|----------|---------|
| RTX 4090 | OWLv2-Large + DINOv3-Large + Depth V2-Large | ~15 FPS |
| RTX 3090 | OWLv2-Large + DINOv3-Base + Depth V2-Large | ~12 FPS |
| RTX 3060 | OWLv2-Base + DINOv3-Base + Depth V2-Base | ~8 FPS |
| GTX 1660 | OWLv2-Base + DINOv3-Small + Depth V2-Small | ~5 FPS |

### CPUé…ç½® (é™çº§)

```python
pipeline = LightLocalization3D(
    detection_model="google/owlv2-base-patch16-ensemble",  # Baseæ¨¡å‹
    feature_model="facebook/dinov3-vits16-pretrain-lvd1689m",  # Smallæ¨¡å‹
    depth_model="depth-anything/Depth-Anything-V2-Small-hf",  # Smallæ¨¡å‹
    device="cpu"
)
```

**é¢„æœŸæ€§èƒ½**: 1-3 FPS (å–å†³äºCPU)

---

## ğŸ“ è¿ç§»æŒ‡å—

### ä»æ—§ä»£ç è¿ç§»

#### æ—§ä»£ç  (Grounding DINO)

```python
from pipeline import LightLocalization3D

pipeline = LightLocalization3D(
    dino_model="IDEA-Research/grounding-dino-tiny",
    depth_model="depth-anything/Depth-Anything-V2-Small-hf"
)

results = pipeline.localize_3d(image, confidence_threshold=0.20)
vis = pipeline.visualize(image, results)
```

#### æ–°ä»£ç  (OWLv2)

```python
from pipeline import LightLocalization3D

pipeline = LightLocalization3D()  # è‡ªåŠ¨ä½¿ç”¨æœ€ä¼˜é…ç½®

result = pipeline.process_image(image, confidence_threshold=0.15)
detections = result['detections']
depth_map = result['depth_map']
```

### APIå˜æ›´

| æ—§æ–¹æ³• | æ–°æ–¹æ³• | è¯´æ˜ |
|--------|--------|------|
| `localize_3d()` | `process_image()` | æ›´æ¸…æ™°çš„å‘½å |
| `visualize()` | å†…ç½®å¯è§†åŒ– | è‡ªåŠ¨åŒ…å«åœ¨ç»“æœä¸­ |
| `dino_modelå‚æ•°` | `detection_modelå‚æ•°` | åæ˜ å®é™…æ¨¡å‹ |
| `-` | `extract_features()` | æ–°å¢ç‰¹å¾æå– |
| `-` | `depth_to_distance()` | æ–°å¢è·ç¦»è®¡ç®— |

---

## ğŸ› æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

#### 1. æ¨¡å‹åŠ è½½å¤±è´¥

**é—®é¢˜**: `Can't load image processor for 'depth-anything/Depth-Anything-V2-Large'`

**è§£å†³**:

- ç¡®ä¿ä½¿ç”¨ `-hf` åç¼€: `Depth-Anything-V2-Large-hf`
- å‡çº§ transformers: `pip install transformers>=4.40.0 -U`

#### 2. CUDAå†…å­˜ä¸è¶³

**é—®é¢˜**: `CUDA out of memory`

**è§£å†³**:

- å¯ç”¨è‡ªåŠ¨é™çº§: `enable_fallback=True` (é»˜è®¤)
- æ‰‹åŠ¨æŒ‡å®šå°æ¨¡å‹: `detection_model="google/owlv2-base-patch16-ensemble"`
- é™ä½å›¾åƒåˆ†è¾¨ç‡: `image = cv2.resize(image, (640, 480))`

#### 3. æ£€æµ‹æ•ˆæœä¸ä½³

**é—®é¢˜**: æ£€æµ‹åˆ°çš„ç¯å…·å¤ªå°‘æˆ–å¤ªå¤š

**è§£å†³**:

- **å¤ªå°‘**: é™ä½é˜ˆå€¼ `confidence_threshold=0.10`
- **å¤ªå¤š**: æé«˜é˜ˆå€¼ `confidence_threshold=0.25`
- **é‡å¤æ£€æµ‹**: æ£€æŸ¥NMSæ˜¯å¦å¯ç”¨ `use_nms=True`

#### 4. è·ç¦»ä¼°è®¡ä¸å‡†

**é—®é¢˜**: è·ç¦»å€¼ä¸åˆç†

**è§£å†³**:

- æä¾›ç›¸æœºå‚æ•°: `camera_params={'min_distance': 1.0, 'max_distance': 5.0}`
- æ£€æŸ¥æ·±åº¦å›¾æ˜¯å¦æ­£å¸¸: `depth_map is not None`
- éªŒè¯ç¯å…·ç±»å‹è¯†åˆ«: æŸ¥çœ‹ `det['label']`

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### æé€Ÿå»ºè®®

1. **ä»…æ£€æµ‹æ¨¡å¼** (ä¸è®¡ç®—æ·±åº¦):

   ```python
   result = pipeline.process_image(image, compute_depth=False)
   # æé€Ÿ ~60%
   ```

2. **ä½¿ç”¨å°æ¨¡å‹**:

   ```python
   pipeline = LightLocalization3D(
       detection_model="google/owlv2-base-patch16-ensemble",
       depth_model="depth-anything/Depth-Anything-V2-Small-hf"
   )
   # æé€Ÿ ~40%, ç²¾åº¦æŸå¤± ~10%
   ```

3. **é™ä½å›¾åƒåˆ†è¾¨ç‡**:

   ```python
   image = cv2.resize(image, (640, 480))
   # æé€Ÿ ~50%, ç²¾åº¦æŸå¤± ~5%
   ```

4. **æ‰¹é‡å¤„ç†** (å¦‚æœé€‚ç”¨):

   ```python
   # æ‰¹é‡æ£€æµ‹å¤šå¼ å›¾åƒå¯ä»¥å…±äº«æ¨¡å‹åŠ è½½æ—¶é—´
   for image_path in image_paths:
       result = pipeline.process_image(cv2.imread(image_path))
   ```

---

## ğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’

### çŸ­æœŸ (1-2å‘¨)

- [ ] æ›´æ–° `evaluate.py` ä½¿ç”¨æ–°æ¶æ„
- [ ] æ›´æ–° `test_quick.py` æµ‹è¯•è„šæœ¬
- [ ] æ›´æ–° `config.yaml` é…ç½®æ–‡ä»¶
- [ ] æ·»åŠ æ‰¹é‡å¤„ç†è„šæœ¬
- [ ] å®Œå–„æ–‡æ¡£å’Œç¤ºä¾‹

### ä¸­æœŸ (1ä¸ªæœˆ)

- [ ] æ·»åŠ æ¨¡å‹é‡åŒ–æ”¯æŒ (æé€Ÿ)
- [ ] å®ç°æ¨¡å‹ç¼“å­˜æœºåˆ¶
- [ ] æ·»åŠ å¤šGPUæ”¯æŒ
- [ ] Webç•Œé¢é›†æˆ
- [ ] Dockerå®¹å™¨åŒ–

### é•¿æœŸ (3ä¸ªæœˆ+)

- [ ] è®­ç»ƒä¸“ç”¨ç¯å…·æ£€æµ‹æ¨¡å‹
- [ ] é›†æˆ3Dé‡å»ºåŠŸèƒ½
- [ ] å®æ—¶è§†é¢‘æµä¼˜åŒ–
- [ ] ç§»åŠ¨ç«¯éƒ¨ç½²
- [ ] äº‘æœåŠ¡API

---

## ğŸ“š å‚è€ƒèµ„æº

### æ¨¡å‹æ–‡æ¡£

- **OWLv2**: <https://huggingface.co/google/owlv2-large-patch14-ensemble>
- **DINOv3**: <https://huggingface.co/facebook/dinov3-vitl16-pretrain-lvd1689m>
- **Depth Anything V2**: <https://huggingface.co/depth-anything/Depth-Anything-V2-Large-hf>

### è®ºæ–‡

- OWLv2: "Scaling Open-Vocabulary Object Detection" (Google, 2023)
- DINOv3: "DINOv2: Learning Robust Visual Features without Supervision" (Meta, 2023)
- Depth Anything V2: "Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data" (2024)

### ColabéªŒè¯

å®Œæ•´çš„éªŒè¯ä»£ç å’Œç»“æœåœ¨:

- `Rex_Omni_DINOv3_Test.ipynb` (æœ¬åœ°)
- Google Colab (å·²éªŒè¯æ‰€æœ‰åŠŸèƒ½)

---

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®,è¯·:

1. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„"æ•…éšœæ’æŸ¥"éƒ¨åˆ†
2. æ£€æŸ¥ GitHub Issues
3. è”ç³»é¡¹ç›®ç»´æŠ¤è€…

---

**æœ€åæ›´æ–°**: 2025å¹´10æœˆ22æ—¥
**æ¶æ„ç‰ˆæœ¬**: v2.0 (OWLv2 + DINOv3 + Depth Anything V2)
**çŠ¶æ€**: âœ… å·²éªŒè¯å¹¶æŠ•äº§
