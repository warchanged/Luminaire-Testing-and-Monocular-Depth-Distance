"""
Gradio Web UI - ç¯å…·3Då®šä½å®æ—¶æ£€æµ‹
æ”¯æŒå›¾åƒä¸Šä¼ ã€æ‘„åƒå¤´å®æ—¶æ£€æµ‹ã€è§†é¢‘å¤„ç†
"""

import gradio as gr
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import torch
from pipeline import LightLocalization3D
import time

# å…¨å±€å˜é‡å­˜å‚¨pipelineå®ä¾‹
pipeline = None

def initialize_pipeline():
    """åˆå§‹åŒ–æ£€æµ‹æµæ°´çº¿"""
    global pipeline
    if pipeline is None:
        print("ğŸš€ åˆå§‹åŒ–ç¯å…·æ£€æµ‹æµæ°´çº¿...")
        pipeline = LightLocalization3D(
            detection_model="google/owlv2-large-patch14-ensemble",
            feature_model="facebook/dinov2-large",
            depth_model="depth-anything/Depth-Anything-V2-Large-hf"
        )
        print("âœ… æµæ°´çº¿åˆå§‹åŒ–å®Œæˆ!")
    return pipeline

def draw_detections(image, detections):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
    # è½¬æ¢ä¸ºPILå›¾åƒ
    if isinstance(image, np.ndarray):
        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    
    draw = ImageDraw.Draw(image)
    
    # å°è¯•åŠ è½½å­—ä½“
    try:
        font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 16)
        font_small = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 12)
    except:
        font = ImageFont.load_default()
        font_small = font
    
    # é¢œè‰²æ–¹æ¡ˆ
    colors = [
        (255, 0, 0), (0, 255, 0), (0, 0, 255),
        (255, 255, 0), (255, 0, 255), (0, 255, 255)
    ]
    
    for idx, det in enumerate(detections):
        box = det['box']
        x1, y1, x2, y2 = map(int, box)
        
        # é€‰æ‹©é¢œè‰²
        color = colors[idx % len(colors)]
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        draw.rectangle([x1, y1, x2, y2], outline=color, width=3)
        
        # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
        label = det['label']
        confidence = det['confidence']
        distance = det.get('distance', None)
        
        if distance:
            text = f"{label}\n{confidence:.1%}\n{distance:.2f}m"
        else:
            text = f"{label}\n{confidence:.1%}"
        
        # ç»˜åˆ¶èƒŒæ™¯æ¡†
        bbox = draw.textbbox((x1, y1-60), text, font=font_small)
        draw.rectangle([bbox[0]-2, bbox[1]-2, bbox[2]+2, bbox[3]+2], fill=(0, 0, 0, 200))
        
        # ç»˜åˆ¶æ–‡æœ¬
        draw.text((x1, y1-60), text, fill=color, font=font_small)
    
    return np.array(image)

def process_image(image, confidence_threshold, show_depth):
    """å¤„ç†å•å¼ å›¾åƒ"""
    try:
        # æ£€æŸ¥è¾“å…¥
        if image is None:
            return None, None, "âŒ è¯·å…ˆä¸Šä¼ å›¾ç‰‡!"
        
        start_time = time.time()
        
        # åˆå§‹åŒ–pipeline
        pipe = initialize_pipeline()
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(image, Image.Image):
            image = np.array(image)
        
        # ç¡®ä¿æ˜¯RGBæ ¼å¼
        if len(image.shape) == 2:  # ç°åº¦å›¾
            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
        elif image.shape[2] == 4:  # RGBA
            image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
        
        print(f"å¤„ç†å›¾åƒ: shape={image.shape}, dtype={image.dtype}, threshold={confidence_threshold}")
        
        # æ‰§è¡Œæ£€æµ‹
        result = pipe.process_image(
            image,
            confidence_threshold=confidence_threshold,
            compute_depth=show_depth,
            compute_distance=show_depth
        )
        
        detections = result['detections']
        depth_map = result.get('depth_map')
        
        # ç»˜åˆ¶æ£€æµ‹ç»“æœ
        output_image = draw_detections(image.copy(), detections)
        
        # å¤„ç†æ—¶é—´
        process_time = time.time() - start_time
        fps = 1.0 / result['timing']['total']
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = f"""
        ### ğŸ“Š æ£€æµ‹ç»Ÿè®¡
        - **æ£€æµ‹æ•°é‡**: {len(detections)} ä¸ªç¯å…·
        - **å¤„ç†æ—¶é—´**: {process_time:.2f}ç§’
        - **FPS**: {fps:.2f}
        - **ç½®ä¿¡åº¦é˜ˆå€¼**: {confidence_threshold:.2f}
        """
        
        # è¯¦ç»†æ£€æµ‹ç»“æœ
        details = "### ğŸ” æ£€æµ‹è¯¦æƒ…\n\n"
        for i, det in enumerate(detections[:10], 1):  # æœ€å¤šæ˜¾ç¤º10ä¸ª
            details += f"**ç›®æ ‡ {i}**\n"
            details += f"- ç±»å‹: {det['label']}\n"
            details += f"- ç½®ä¿¡åº¦: {det['confidence']:.2%}\n"
            if det.get('distance'):
                details += f"- è·ç¦»: {det['distance']:.2f}m\n"
            details += "\n"
        
        # æ·±åº¦å›¾å¯è§†åŒ–
        depth_image = None
        if show_depth and depth_map is not None:
            import matplotlib.pyplot as plt
            import matplotlib
            matplotlib.use('Agg')
            
            fig, ax = plt.subplots(figsize=(8, 6))
            im = ax.imshow(depth_map, cmap='plasma')
            ax.set_title('æ·±åº¦ä¼°è®¡')
            ax.axis('off')
            plt.colorbar(im, ax=ax, label='æ·±åº¦ (å½’ä¸€åŒ–)')
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ (ä½¿ç”¨æ–°API)
            fig.canvas.draw()
            # ä½¿ç”¨ buffer_rgba() ä»£æ›¿å·²å¼ƒç”¨çš„ tostring_rgb()
            buf = fig.canvas.buffer_rgba()
            depth_image = np.asarray(buf)
            # è½¬æ¢RGBAåˆ°RGB
            depth_image = depth_image[:, :, :3]
            plt.close(fig)
        
        return output_image, depth_image, stats + "\n" + details
        
    except Exception as e:
        import traceback
        error_msg = f"âŒ å¤„ç†å¤±è´¥: {str(e)}\n\n```\n{traceback.format_exc()}\n```"
        return image, None, error_msg

def process_video_frame(frame, confidence_threshold):
    """å¤„ç†è§†é¢‘å¸§(ç”¨äºå®æ—¶æ‘„åƒå¤´)"""
    pipe = initialize_pipeline()
    
    # æ‰§è¡Œæ£€æµ‹
    result = pipe.process_image(
        frame,
        confidence_threshold=confidence_threshold,
        compute_depth=False,  # å®æ—¶æ¨¡å¼å…³é—­æ·±åº¦è®¡ç®—ä»¥æé«˜é€Ÿåº¦
        compute_distance=False
    )
    
    # ç»˜åˆ¶ç»“æœ
    output = draw_detections(frame, result['detections'])
    
    # æ·»åŠ FPSæ˜¾ç¤º
    fps = 1.0 / result['timing']['total']
    cv2.putText(output, f"FPS: {fps:.1f}", (10, 30), 
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.putText(output, f"Lights: {len(result['detections'])}", (10, 70),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    
    return output

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="ç¯å…·3Då®šä½æ£€æµ‹ç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ”¦ ç¯å…·3Då®šä½æ£€æµ‹ç³»ç»Ÿ
    
    åŸºäº **OWLv2 + DINOv2 + Depth Anything V2** çš„æ™ºèƒ½ç¯å…·æ£€æµ‹ä¸3Då®šä½
    
    æ”¯æŒ30+ç§å®¤å†…ç¯å…·ç±»å‹ | é›¶æ ·æœ¬æ£€æµ‹ | ç²¾ç¡®è·ç¦»ä¼°è®¡
    """)
    
    with gr.Tabs():
        # Tab 1: å›¾åƒä¸Šä¼ æ£€æµ‹
        with gr.Tab("ğŸ“¸ å›¾åƒæ£€æµ‹"):
            with gr.Row():
                with gr.Column():
                    input_image = gr.Image(label="ä¸Šä¼ å›¾åƒ", type="numpy")
                    confidence_slider = gr.Slider(
                        minimum=0.05,
                        maximum=0.5,
                        value=0.15,
                        step=0.05,
                        label="ç½®ä¿¡åº¦é˜ˆå€¼"
                    )
                    show_depth_check = gr.Checkbox(
                        label="æ˜¾ç¤ºæ·±åº¦å›¾",
                        value=True
                    )
                    detect_btn = gr.Button("ğŸ” å¼€å§‹æ£€æµ‹", variant="primary")
                
                with gr.Column():
                    output_image = gr.Image(label="æ£€æµ‹ç»“æœ")
                    depth_image = gr.Image(label="æ·±åº¦å›¾", visible=True)
            
            with gr.Row():
                stats_output = gr.Markdown(label="æ£€æµ‹ç»Ÿè®¡")
            
            detect_btn.click(
                fn=process_image,
                inputs=[input_image, confidence_slider, show_depth_check],
                outputs=[output_image, depth_image, stats_output]
            )
        
        # Tab 2: å®æ—¶æ‘„åƒå¤´æ£€æµ‹ (ç®€åŒ–ç‰ˆ - ä½¿ç”¨Imageç»„ä»¶)
        with gr.Tab("ğŸ¥ å®æ—¶æ£€æµ‹"):
            gr.Markdown("""
            ### ä½¿ç”¨è¯´æ˜
            1. ä½¿ç”¨æµè§ˆå™¨çš„æ‘„åƒå¤´æƒé™
            2. ä¸Šä¼ å›¾ç‰‡æˆ–ä½¿ç”¨ä¸‹æ–¹çš„è§†é¢‘å¤„ç†åŠŸèƒ½
            3. è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼ä¼˜åŒ–æ£€æµ‹æ•ˆæœ
            
            **æç¤º**: å¦‚éœ€çœŸæ­£çš„å®æ—¶æ£€æµ‹,è¯·ä½¿ç”¨æœ¬åœ°çš„ `webcam_client.html` æ–‡ä»¶
            """)
            
            with gr.Row():
                with gr.Column():
                    video_input = gr.Image(label="ä¸Šä¼ å›¾ç‰‡æˆ–æˆªå›¾", type="numpy")
                    video_confidence = gr.Slider(
                        minimum=0.05,
                        maximum=0.5,
                        value=0.15,
                        step=0.05,
                        label="ç½®ä¿¡åº¦é˜ˆå€¼"
                    )
                    process_btn = gr.Button("ğŸ” å¤„ç†å›¾åƒ", variant="primary")
                
                with gr.Column():
                    video_output = gr.Image(label="æ£€æµ‹ç»“æœ")
                    video_stats = gr.Markdown(label="ç»Ÿè®¡ä¿¡æ¯")
            
            process_btn.click(
                fn=lambda img, conf: process_image(img, conf, False),
                inputs=[video_input, video_confidence],
                outputs=[video_output, gr.Image(visible=False), video_stats]
            )
        
        # Tab 3: å®æ—¶æ‘„åƒå¤´ä½¿ç”¨æŒ‡å—
        with gr.Tab("ğŸ“¹ çœŸå®æ—¶æ£€æµ‹"):
            gr.Markdown("""
            # ğŸ¥ æœ¬åœ°æ‘„åƒå¤´å®æ—¶æ£€æµ‹
            
            ç”±äºGradioæ–°ç‰ˆæœ¬é™åˆ¶,Webç•Œé¢ä¸æ”¯æŒç›´æ¥è°ƒç”¨æ‘„åƒå¤´æµã€‚
            
            è¯·ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•å®ç°çœŸæ­£çš„å®æ—¶æ£€æµ‹:
            
            ---
            
            ## æ–¹æ³•1: ä½¿ç”¨ webcam_client.html (æ¨è)
            
            ### æ­¥éª¤:
            1. åœ¨æœ¬åœ°ç”µè„‘æ‰“å¼€ `webcam_client.html` æ–‡ä»¶
            2. ç¡®è®¤æœåŠ¡å™¨åœ°å€: `http://52.18.175.128:7860`
            3. ç‚¹å‡» "ğŸ“¹ å¯åŠ¨æ‘„åƒå¤´" æŒ‰é’®
            4. æˆæƒæµè§ˆå™¨ä½¿ç”¨æ‘„åƒå¤´
            5. å®æ—¶æ£€æµ‹å¼€å§‹!
            
            ### ç‰¹ç‚¹:
            - âœ… ç²¾ç¾çš„UIç•Œé¢
            - âœ… å®æ—¶FPSæ˜¾ç¤º
            - âœ… æ£€æµ‹æ•°é‡ç»Ÿè®¡
            - âœ… å»¶è¿Ÿç›‘æ§
            - âœ… æ€»å¸§æ•°è®¡æ•°
            
            ---
            
            ## æ–¹æ³•2: ä½¿ç”¨Pythonè„šæœ¬
            
            ```bash
            # SSHåˆ°æœåŠ¡å™¨
            cd /mnt/ai/luminaire-detection
            source venv/bin/activate
            
            # è¿è¡Œå®æ—¶æ£€æµ‹è„šæœ¬
            python realtime.py
            ```
            
            ---
            
            ## æ–¹æ³•3: å›¾ç‰‡/æˆªå›¾æ£€æµ‹
            
            ä½¿ç”¨ "ğŸ“¸ å›¾åƒæ£€æµ‹" æ ‡ç­¾:
            1. ä»æ‘„åƒå¤´æˆªå›¾
            2. ä¸Šä¼ æˆªå›¾
            3. è·å¾—å®Œæ•´åˆ†æ(å«æ·±åº¦å›¾)
            
            ---
            
            ## ä¸‹è½½ webcam_client.html
            
            æ–‡ä»¶ä½ç½®: é¡¹ç›®æ ¹ç›®å½•çš„ `webcam_client.html`
            
            æˆ–è®¿é—®: [GitHubä»“åº“](https://github.com/warchanged/Luminaire-Testing-and-Monocular-Depth-Distance/blob/main/webcam_client.html)
            """)
        
        # Tab 4: ç³»ç»Ÿä¿¡æ¯
        with gr.Tab("â„¹ï¸ ç³»ç»Ÿä¿¡æ¯"):
            gr.Markdown("""
            ### æŠ€æœ¯æ¶æ„
            
            | ç»„ä»¶ | æ¨¡å‹ | ç”¨é€” |
            |------|------|------|
            | **æ£€æµ‹å™¨** | OWLv2-Large | é›¶æ ·æœ¬ç›®æ ‡æ£€æµ‹ |
            | **ç‰¹å¾æå–** | DINOv2-Large | è‡ªç›‘ç£è§†è§‰ç‰¹å¾ |
            | **æ·±åº¦ä¼°è®¡** | Depth Anything V2 | å•ç›®æ·±åº¦ä¼°è®¡ |
            
            ### æ”¯æŒçš„ç¯å…·ç±»å‹
            
            - ğŸ® åŠç¯ç±»: chandelier, pendant light, hanging lamp
            - ğŸ’¡ å¸é¡¶ç¯: ceiling light, flush mount, recessed light
            - ğŸ•¯ï¸ å£ç¯: wall lamp, wall sconce
            - ğŸ›‹ï¸ å°ç¯: table lamp, desk lamp
            - ğŸŒŸ å°„ç¯: spotlight, track light
            - âœ¨ LEDç¯: LED panel, LED strip
            - ... å…±30+ç§ç±»å‹
            
            ### æ€§èƒ½æŒ‡æ ‡
            
            - **æ£€æµ‹ç²¾åº¦**: 90%+ (å®¤å†…åœºæ™¯)
            - **å¤„ç†é€Ÿåº¦**: 1-3 FPS (GPUæ¨¡å¼)
            - **æ·±åº¦ç²¾åº¦**: Â±0.3m (2-5mè·ç¦»)
            
            ### GitHub
            
            [ğŸ”— é¡¹ç›®åœ°å€](https://github.com/warchanged/Luminaire-Testing-and-Monocular-Depth-Distance)
            """)

if __name__ == "__main__":
    # å¯åŠ¨æœåŠ¡å™¨
    demo.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=7860,
        share=False,  # ä¸ä½¿ç”¨gradio.liveé“¾æ¥
        show_error=True
    )
